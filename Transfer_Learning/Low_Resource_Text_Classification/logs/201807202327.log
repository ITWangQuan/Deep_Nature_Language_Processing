2018-07-20 23:27:15,203 - main.py[line:62] - INFO: words index loaded
2018-07-20 23:27:41,143 - main.py[line:65] - INFO: word embedding loaded
2018-07-20 23:27:41,146 - tf_logging.py[line:82] - INFO: Using config: {'_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E8417652E8>, '_model_dir': 'D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000', '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_session_config': None, '_task_type': 'worker', '_master': '', '_keep_checkpoint_max': 1, '_is_chief': True, '_tf_random_seed': None, '_service': None, '_log_step_count_steps': 100}
2018-07-20 23:27:44,023 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:27:58,535 - tf_logging.py[line:82] - INFO: Saving checkpoints for 1 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:01,251 - tf_logging.py[line:82] - INFO: loss = 1.385421, step = 1
2018-07-20 23:28:01,252 - tf_logging.py[line:82] - INFO: lr = 0.0005, global_step = 1
2018-07-20 23:28:05,260 - tf_logging.py[line:82] - INFO: Saving checkpoints for 20 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:07,719 - tf_logging.py[line:82] - INFO: Loss for final step: 1.2710702.
2018-07-20 23:28:09,809 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:28:10,232 - tf_logging.py[line:82] - INFO: Restoring parameters from D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt-20
2018-07-20 23:28:17,274 - tf_logging.py[line:82] - INFO: Saving checkpoints for 21 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:19,602 - tf_logging.py[line:82] - INFO: loss = 1.1838313, step = 21
2018-07-20 23:28:19,602 - tf_logging.py[line:82] - INFO: lr = 0.00049948733, global_step = 21
2018-07-20 23:28:23,425 - tf_logging.py[line:82] - INFO: Saving checkpoints for 40 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:25,863 - tf_logging.py[line:82] - INFO: Loss for final step: 1.1837757.
2018-07-20 23:28:28,136 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:28:28,558 - tf_logging.py[line:82] - INFO: Restoring parameters from D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt-40
2018-07-20 23:28:35,588 - tf_logging.py[line:82] - INFO: Saving checkpoints for 41 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:38,056 - tf_logging.py[line:82] - INFO: loss = 1.1185439, step = 41
2018-07-20 23:28:38,056 - tf_logging.py[line:82] - INFO: lr = 0.0004989752, global_step = 41
2018-07-20 23:28:41,807 - tf_logging.py[line:82] - INFO: Saving checkpoints for 60 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:44,197 - tf_logging.py[line:82] - INFO: Loss for final step: 0.9947946.
2018-07-20 23:28:46,510 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:28:46,892 - tf_logging.py[line:82] - INFO: Restoring parameters from D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt-60
2018-07-20 23:28:53,647 - tf_logging.py[line:82] - INFO: Saving checkpoints for 61 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:28:56,123 - tf_logging.py[line:82] - INFO: loss = 1.0198839, step = 61
2018-07-20 23:28:56,123 - tf_logging.py[line:82] - INFO: lr = 0.0004984636, global_step = 61
2018-07-20 23:28:59,857 - tf_logging.py[line:82] - INFO: Saving checkpoints for 80 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:29:02,296 - tf_logging.py[line:82] - INFO: Loss for final step: 0.9334943.
2018-07-20 23:29:04,654 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:29:05,046 - tf_logging.py[line:82] - INFO: Restoring parameters from D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt-80
2018-07-20 23:29:12,062 - tf_logging.py[line:82] - INFO: Saving checkpoints for 81 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:29:14,391 - tf_logging.py[line:82] - INFO: loss = 1.0061647, step = 81
2018-07-20 23:29:14,391 - tf_logging.py[line:82] - INFO: lr = 0.0004979525, global_step = 81
2018-07-20 23:29:18,161 - tf_logging.py[line:82] - INFO: Saving checkpoints for 100 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt.
2018-07-20 23:29:20,552 - tf_logging.py[line:82] - INFO: Loss for final step: 1.0359358.
2018-07-20 23:29:20,552 - main.py[line:31] - INFO: evaluating model on 1000 data samples....
2018-07-20 23:29:22,944 - tf_logging.py[line:82] - INFO: Starting evaluation at 2018-07-20-22:29:22
2018-07-20 23:29:23,347 - tf_logging.py[line:82] - INFO: Restoring parameters from D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_1000\model.ckpt-100
2018-07-20 23:29:25,000 - tf_logging.py[line:82] - INFO: Finished evaluation at 2018-07-20-22:29:25
2018-07-20 23:29:25,001 - tf_logging.py[line:82] - INFO: Saving dict for global step 100: accuracy = 0.6166667, confusion_matrix = [[64 14  7  0]
 [16 77 34  0]
 [ 2 20 44  0]
 [ 0  1 21  0]], global_step = 100, loss = 0.9297686
2018-07-20 23:29:28,539 - tf_logging.py[line:86] - WARNING: Skipping summary for confusion_matrix, must be a float, np.float32, np.int64, np.int32 or int.
2018-07-20 23:29:28,651 - main.py[line:33] - INFO: Val set accuracy: 0.617

2018-07-20 23:29:28,652 - tf_logging.py[line:82] - INFO: Using config: {'_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001E8417652E8>, '_model_dir': 'D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_2000', '_num_ps_replicas': 0, '_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_session_config': None, '_task_type': 'worker', '_master': '', '_keep_checkpoint_max': 1, '_is_chief': True, '_tf_random_seed': None, '_service': None, '_log_step_count_steps': 100}
2018-07-20 23:29:30,757 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:29:41,245 - tf_logging.py[line:82] - INFO: Saving checkpoints for 1 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_2000\model.ckpt.
2018-07-20 23:29:43,937 - tf_logging.py[line:82] - INFO: loss = 1.3863602, step = 1
2018-07-20 23:29:43,938 - tf_logging.py[line:82] - INFO: lr = 0.0005, global_step = 1
2018-07-20 23:29:51,444 - tf_logging.py[line:82] - INFO: Saving checkpoints for 40 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_2000\model.ckpt.
2018-07-20 23:29:53,773 - tf_logging.py[line:82] - INFO: Loss for final step: 1.1695036.
2018-07-20 23:29:55,922 - tf_logging.py[line:82] - INFO: Create CheckpointSaverHook.
2018-07-20 23:29:56,598 - tf_logging.py[line:82] - INFO: Restoring parameters from D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_2000\model.ckpt-40
2018-07-20 23:30:03,979 - tf_logging.py[line:82] - INFO: Saving checkpoints for 41 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_2000\model.ckpt.
2018-07-20 23:30:06,356 - tf_logging.py[line:82] - INFO: loss = 1.1403035, step = 41
2018-07-20 23:30:06,356 - tf_logging.py[line:82] - INFO: lr = 0.0004989752, global_step = 41
2018-07-20 23:30:13,864 - tf_logging.py[line:82] - INFO: Saving checkpoints for 80 into D:/PycharmWorkSpace/Gits/Deep_Nature_Language_Processing/Transfer_Learning/Low_Resource_Text_Classification/model/saved_model/model_2000\model.ckpt.
2018-07-20 23:30:16,250 - tf_logging.py[line:82] - INFO: Loss for final step: 0.89984775.
